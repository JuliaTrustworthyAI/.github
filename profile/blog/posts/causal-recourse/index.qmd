---
title: "When Causal meets Recourse"
subtitle: "Counterfactual Explanations through Structural Causal Models"
bibliography: bib.bib
date: '2024-09-03'
description: |
    This post introduces a new tool in CounterfactualExplanations.jl, enhancing the package with causal reasoning to generate counterfactual explanations. The functionality can be used to explain machine learning algorithms developed in Julia and other popular programming languages like Python and R. Unlike traditional counterfactual generators, this approach utilizes causal information to perturb features intelligently.
author: 
    - name: Jorge Luiz Franco 
      url: https://www.linkedin.com/in/jorgelwyz/
categories:
  - counterfactuals
  - explainable AI
  - causality
  - Julia
image: www/intro.gif
execute:
  eval: false
  echo: true
draft: false
---

# Introduction

In recent years, the need for interpretable and explainable AI has surged, particularly in high-stakes domains. Counterfactual explanations provide a means to understand how changes to input features could alter the outcomes of machine learning models. This blog post presents a new tool in the CounterfactualExplanations.jl package, developed during my JSoC (Julia Summer of Code) project, which incorporates causal reasoning into counterfactual generation.

# Project Overview

This project aimed to enhance the CounterfactualExplanations.jl package by infusing it with a robust mathematical foundation for minimal algorithmic recourse, based on the principles of causal reasoning [@karimi2021]. 

## Key Contributions

During the project, I contributed to two key repositories:

1. **CounterfactualExplanations.jl**: Developed a new tool for generating counterfactual explanations using causal information. This allows users to create smarter perturbations rather than random adjustments, ultimately providing more meaningful insights.

2. **CausalInference.jl**: Implemented a Structural Causal Model (SCM) structure that extracts information from data, laying the groundwork for the causal reasoning capabilities in CounterfactualExplanations.jl.

This was an amazing experience, not just experience contribute to two repositories simultaneously, but also to work with the mantainers of these repos. I learned a lot about the Julia language and the Julia community. This was possible because of the mentorship of Patrick Altmeyer(CounterfactualExplanations) and Moritz Schauer (CausalInference), who guided me throughout the project and are amazing researchers.



## The `MINTGenerator`

In this project, we developed the MINTGenerator, a counterfactual generator based on the Recourse through Minimal
Intervention (MINT) method proposed by @karimi2021.

## Description

The MINTGenerator incorporates causal reeasoning in algorithm recourse to achieve minimal interventions when generating a counterfactual explanation. In this sense, the main ideia is that just perturbating a black box model without taking into account the causal relations in the data can guide to misleading recommendations. Here we now shift to a perspective where every action/pertubation is an intervetion in the causal graph of the problem, thus the change is not made just in the intervened upon variable, but also in its childs in the causal structure. The generator utilizes a Structural Causal Model(SCM) to encode the variables in a way that causal effects are propagated and uses a generic gradient-based generator to create the search path, that is, any gradient-base generator (ECCo, REVISE, Watcher, ...) can be used with the MINT SCM encoder to generate counterfactual samples in latent space for minimal intervetions algorithm recourse.

The MINT algorithm minimizes a loss function that combines the causal constraints of the SCM and the distance between the generated counterfactual and the original input. Since we want a gradient-based generator, we need to pass the constrained optimizaiton problem into an unconstrained one and we do this by using the Lagrangian. Initially, as defined in [@karimi2021], we aim to aim to find the minimal cost set of actions $A$ (in the form of structural interventions) that results in a counterfactual instance yielding the favorable output from $h$,


\begin{aligned}

A^* \in \arg\min_A \text{cost}(A; \mathbf{x}_F)\\
\textrm{s.t.} \quad  h(\mathbf{x}_{SCF}) \neq h(\mathbf{x}_F) \; \; \text{,}\\

\end{aligned} 

where $\mathbf{x}_F$ is the original input, $\mathbf{x}_{SCF}$ is the counterfactual instance, and $h$ is the black-box model. We use the $\mathbf{x}_{SCF}$ terminology because the counterfactual is derived from the SCM,

\begin{equation}

x_{SCF_i} = 
\begin{cases}
x_{F_i} + \delta_i, & \text{if } i \in I \\
x_{F_i} + f_i(\text{pa}_{SCF_i}) - f_i(\text{pa}_{F_i}), & \text{if } i \notin I  \; \; \text{,}
\end{cases} 

\end{equation}

where $I$ is the set of intervened upon variables, $f_i$ is the function that generates the value of the variable $i$ given its parents, and $\text{pa}_{SCF_i}$ and $\text{pa}_{F_i}$ are the parents of the variable $i$ in the counterfactual and original instance, respectively. This closed formula for the decision variable $\mathbf{x}_{SCF}$ is what makes possible to use a gradient-based generator, since with it the lagrangian is differentiable,

\begin{equation}
\mathcal{L}(A ; \lambda) = \text{cost}(A; \mathbf{x}_F) + \lambda \left(h(\mathbf{x}_{SCF}) - h(\mathbf{x}_F) \right) \; \; \text{,}
\end{equation}

or in simple terms and more standard, since $\lambda$ is constant,

\begin{equation}
\mathcal{L_{\texttt{MINT}}}(\mathbf{x}_{SCF}) = \lambda \text{cost}(\mathbf{x}_{SCF}; \mathbf{x}_F) + \text{yloss}(\mathbf{x}_{SCF},y^*) \; \; \text{,}
\end{equation}

where $y^*$ is clearly $h(x_F)$ and $\text{yloss}$ is : 

\begin{equation}  
\text{yloss}(\mathbf{x}_{SCF}, y^*) = h \left(\left\{ x_{F_i} + \delta_i [i \in I] + \left(f_i(\text{pa}_{SCF_i}) - f_i(\text{pa}_{F_i}) \right) [i \notin I] \right\}_{i=1}^n \right) - y^* \; \; \text{.} 
\end{equation}



## Implementation

### `CausalInference.jl`

In terms of implementation, we need to capture the causal relations from the data, that's where `CausalInference.jl` comes in. However, before the project, the package did not have a SCM structure, in the sense that the methods just captured the topological Directed Acyclic Graph (DAG) that showed the causality ruling the data, that is, no causal structural equations were provided,

```{julia}
using CausalInference
using Plots, GraphRecipes
using Random
Random.seed!(1)

N = 2000 # number of data points

x = randn(N)
v = x + randn(N)*0.25
w = x + randn(N)*0.25
z = v + w + randn(N)*0.25
s = z + randn(N)*0.25

df = (x=x, v=v, w=w, z=z, s=s)

est_g, score = ges(df; penalty=1.0, parallel=true)

graphplot(pdag2dag!(est_g), names= [String(k) for k in keys(df)])
```

So, our goal was given the DAG provided by the `ges` method in the causal discovery [@ges2003], generate equations that rules each of these causal relations, represented in the DAG as directed edges. The SCM is the union of the DAG and these causal equations, that is, the SCM is a tuple $(G, \mathbf{f})$, where $G$ is the DAG and $\mathbf{f}$ is the set of functions that generates the value of each variable given its parents. 

Our solution for constructing the structural causal equations was to assume that the data was generated by a linear model, ie, the causal relations were linear. For the DAG provided in the code example we derive


$$ v = \mathcal{b}_v $$

$$ x = \mathcal{a}_{v \to x} v + \mathcal{b}_x $$

$$ w = \mathcal{a}_{x \to w} x + \mathcal{b}_w $$

$$ z = \mathcal{a}_{v \to z} v+ \mathcal{a}_{w \to z} w + \mathcal{b}_z $$

$$ s = \mathcal{a}_{z \to s} z + \mathcal{b}_s $$

and that's the tricky thing, as we can see these causal equations are different than the ones that generated the data, but they are the ones that respect the causal system obtained from the obtained DAG. Here $\mathcal{b}_i$ and $\mathcal{a}_{i \to j}$ are the intercept term and the coefficient obtained from the linear regression, respectively. To correctly solve the linear regression respecting the dependencies of the causal graph, we use `topological_sort_by_dfs` from `Graphs.jl`.

Now, with the SCM structure in hand, we see that the representation could be a struct containing the DAG and the coefficients/intercepts of the causal equations, this maps exactly the tuple $(G, \mathbf{f})$ that we defined. However, since we need these equations to be differentiable, we need to define a function that takes the SCM and returns the value of the variable given its parents and using just the coefficients and the DAG, lead to errors, because `AutoDiff` does not deal well with functions that are conditioned (`if` statements). So, we need to define a way to retrieve the system of causal equations in a smooth way and that's where the `causal_effects` matrix comes to the rescue.

Let the factual vector of features be denoted as:

$$
\mathbf{x}_F = 
\begin{bmatrix}
x_{F_1} \\
x_{F_2} \\
x_{F_3} \\
\vdots \\
x_{F_n}
\end{bmatrix}
$$

Let the `causal_effects` matrix be:

$$
\mathbf{C} =
\begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} & b_1 \\
a_{21} & a_{22} & \cdots & a_{2n} & b_2 \\
a_{31} & a_{32} & \cdots & a_{3n} & b_3 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn} & b_n \\
\end{bmatrix}
$$

Here, $a_{ij}$ represents the coefficient from the causal effect of $x_{F_j}$ on $x_{F_i}$, and $b_i$ represents the intercept term for the variable $x_{F_i}$.

The matrix multiplication of the `causal_effects` matrix with the factual vector (excluding the bias term) is given by:

$$
\mathbf{C}_{:, 1:n} \cdot \mathbf{x}_F =
\begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
a_{31} & a_{32} & \cdots & a_{3n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{bmatrix}
\begin{bmatrix}
x_{F_1} \\
x_{F_2} \\
x_{F_3} \\
\vdots \\
x_{F_n}
\end{bmatrix}
$$

Finally, we add the bias term:

$$
\mathbf{x}_{SCF} = \mathbf{C}_{:, 1:n} \cdot \mathbf{x}_F + 
\begin{bmatrix}
b_1 \\
b_2 \\
b_3 \\
\vdots \\
b_n
\end{bmatrix}
$$

In expanded form:

$$
\mathbf{x}_{SCF_i} = a_{i1} x_{F_1} + a_{i2} x_{F_2} + \cdots + a_{in} x_{F_n} + b_i, \quad \forall i = 1, 2, \dots, n
$$

This equation shows how each counterfactual variable $x_{SCF_i}$ is generated as a linear combination of the factual inputs $x_{F_j}$ based on the causal effects matrix, with an intercept term $b_i$ added for each variable.

One can note that the `orphan` nodes, that is, the nodes that do not have parents in the DAG, are going to be equal to the intercept term $\mathcal{b}_\hat{o}$. The intuition behind this is that when we do the linear regression, variables that have no causal parents are just equal to the unconditional mean of the variable, i.e, we get $x_{SCF_\hat{o}} = \mathbb{E}(x_\hat{o})$. Because of this, in some cases a better understanding of the regression is needed, so the residuals are also part of the SCM structure,

```{julia}
struct SCM
    variables::Vector{String}
    coefficients::Vector{Vector{Float64}}
    residuals::Vector{Vector{Float64}}
    dag::DiGraph
    causal_effects::Matrix{Float64}
end
```

### `CounterfactualExplanations.jl` 

Now, we need to go into the optimization problem previously described. We seek to minimize the lagrangian function we defined where now we have a differentiable function. The standard way to implement generators in `CounterfactualExplanations.jl` is to use `AutoDiff` exactly using composable functions in the lagrangian. The definition of $\mathcal{L_{\texttt{MINT}}}$ is in the same shape of the the others gradient-based generators in the package, so the optimization is straightforward. However, we needed some way to pass the $x_F$ into the $x_{SCF}$ and that's where `transformer.jl` comes in. This is where `InputTransformer`s are defined in the package and in some way this is what we are doing, we are passing our factual to the "latent" causal space of the counterfactual. Our first step is to create a new kind of `InputTransformer` that is the SCM itself,

```{julia}
const TypedInputTransformer = Union{
    Type{<:StatsBase.AbstractDataTransform},
    Type{<:MultivariateStats.AbstractDimensionalityReduction},
    Type{<:GenerativeModels.AbstractGenerativeModel},
    Type{<:CausalInference.SCM} # The SCM transfromer
}
```

and then we need a way to create this transformer, that's where we "overload" `fit_transformer` using `CausalInferece.jl`, 

```{julia}
function fit_transformer(
    data::CounterfactualData, input_encoder::Type{<:CausalInference.SCM}; kwargs...
)
    t = Tables.table(transpose(data.X))
    est_g, score = CausalInference.ges(t; penalty=1.0, parallel=true)
    est_dag = CausalInference.pdag2dag!(est_g)
    scm = CausalInference.estimate_equations(t, est_dag)
    return scm
end
```  
... We are getting there! However, now comes the hardest part, where this is placed?





# Conclusion

<!-- In conclusion, this project has successfully integrated causal reasoning into the CounterfactualExplanations.jl package, providing a valuable tool for generating counterfactual explanations that are not only interpretable but also actionable. -->

# References
